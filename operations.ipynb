{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da3f7c09-10f7-4b89-9582-119c4bfa5490",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../../../../../../includes/main/python/global_operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab8729c2-5931-4512-be44-443e4abf743b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../../schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3920b2c-af61-429a-869a-c8a1fe63793b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./system_to_vehicle_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0edd7879-5bd5-43e2-a4e2-6b577a65f359",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "PARTITION_COLUMN = 'p_Date'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce2875b8-faf9-48ce-90a5-88dfb4de92d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# sample paylaod as per 12/10/2022\n",
    "\n",
    "# {\n",
    "#   \"events\": \"[]\", \n",
    "#   \"type\": \"GPSData\", \n",
    "#   \"sentAt\": \"2022/07/31 11:13 \", \n",
    "#   \"supplier\": \"Icomera\", \n",
    "#   \"system_ID\": \"1450350259\"\n",
    "#   \"dataPoint\": [\n",
    "#     {\n",
    "#       \"system_name\": \"350259\", \n",
    "#       \"mode\": 3, \n",
    "#       \"position\": {\n",
    "#         \"altitude\": 60.9, \n",
    "#         \"longitude\": -2.432628, \n",
    "#         \"latitude\": 53.088512, \n",
    "#         \"type\": \"GeoPosition\"\n",
    "#       }, \n",
    "#       \"speed\": 0.005, \n",
    "#       \"type\": \"UnitPoint\", \n",
    "#       \"deviceCount\": 23, \n",
    "#       \"system\": \"1450350259\", \n",
    "#       \"age\": \"1\", \n",
    "#       \"numberOfSatellites\": 10, \n",
    "#       \"time\": \"1659262386\", \n",
    "#       \"cmg\": 345.56, \n",
    "#       \"system_ID\": \"1450350259\"\n",
    "#     }, \n",
    "#     {\n",
    "#       \"system_name\": \"350259\", \n",
    "#       \"mode\": 0, \n",
    "#       \"position\": {\n",
    "#         \"altitude\": 60.9, \n",
    "#         \"longitude\": -2.432628, \n",
    "#         \"latitude\": 53.088512, \n",
    "#         \"type\": \"GeoPosition\"\n",
    "#       }, \n",
    "#       \"speed\": 0.005, \n",
    "#       \"type\": \"UnitPoint\", \n",
    "#       \"deviceCount\": 23, \n",
    "#       \"system\": \"1450350259\", \n",
    "#       \"age\": \"2\", \n",
    "#       \"numberOfSatellites\": 10, \n",
    "#       \"time\": \"1659262386\", \n",
    "#       \"cmg\": 345.56, \n",
    "#       \"system_ID\": \"1450350259\"\n",
    "#     }\n",
    "#   ]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "193503e5-b8e4-4172-b16e-4b127e6c1d7e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_stream_raw(spark: SparkSession, ehConf: dict) -> DataFrame:\n",
    "    eh_schema = \"\"\"\n",
    "      `body` BINARY,`partition` STRING,`offset` STRING,`sequenceNumber` BIGINT,`enqueuedTime` TIMESTAMP,`publisher` STRING,`partitionKey` STRING,`properties` MAP<STRING, STRING>,`systemProperties` MAP<STRING, STRING>\n",
    "     \"\"\"\n",
    "    return spark.readStream.format(\"eventhubs\").schema(eh_schema).options(**ehConf).load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "250d801a-435b-4539-830a-4c0ea0fdf35c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def transform_raw(raw: DataFrame) -> DataFrame:\n",
    "    return raw.select(\n",
    "        F.col(\"*\"),\n",
    "        F.col(\"body\").cast(\"string\").alias(\"Body_Decoded\"),\n",
    "        F.lit(\"evhns-gps-prod-ne.evh-gps-prod-ne\").alias(\"_Data_Source\"),  # TODO: Find way to parameterise the $env\n",
    "        F.col(\"enqueuedTime\").alias(\"_Ingest_Timestamp\"),\n",
    "        F.lit(\"new\").alias(\"_Status\"),\n",
    "        F.col(\"enqueuedTime\").cast(\"date\").alias(\"p_Ingest_Date\"),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "309e7b1a-f09f-4c90-98d7-e22daca3b3a3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def compute_date_range(df:DataFrame, date_field:str) -> (str, str):\n",
    "    min_date = df.selectExpr(f\"min({date_field})\").collect()[0][0]\n",
    "    max_date = df.selectExpr(f\"max({date_field})\").collect()[0][0]\n",
    "    return str(min_date), str(max_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d37a36ac-7d6b-4335-8878-213062ef06a6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_rake_hist_by_unit_df(min_date:str, max_date:str) -> DataFrame:\n",
    "    rake_history_df = load_rake_history()\n",
    "    return (\n",
    "        rake_history_df\n",
    "        .filter((rake_history_df.Date >= min_date) & (rake_history_df.Date <= max_date))\n",
    "        .select(\"Date\", \"Vehicle\", \"Unit\", \"TOC\", \"Fleet_Name\", \"Vehicle_Class\", \"Owning_Company\", \"Vehicle_Sub_Class\")\n",
    "        .withColumnRenamed(\"Date\", \"Rake_Date\")\n",
    "        .dropDuplicates(['Unit', 'Rake_Date'])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "628577ba-818d-4e61-8704-e6949446015b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_rake_hist_by_vehicle_df(min_date:str, max_date:str) -> DataFrame:\n",
    "    rake_history_df = load_rake_history()\n",
    "    return (\n",
    "        rake_history_df\n",
    "        .filter((rake_history_df.Date >= min_date) & (rake_history_df.Date <= max_date))\n",
    "        .select(\"Date\", \"Vehicle\", \"Unit\", \"TOC\", \"Fleet_Name\", \"Vehicle_Class\", \"Owning_Company\", \"Vehicle_Sub_Class\")\n",
    "        .withColumnRenamed(\"Date\", \"Rake_Date\")\n",
    "        .dropDuplicates(['Vehicle', 'Rake_Date'])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2d758af-25f7-4a61-b85f-a0287b8eaf35",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def add_rake_metadata(df: DataFrame) -> DataFrame:\n",
    "    min_date,max_date=compute_date_range(df, 'Date')\n",
    "    rake_hist_by_unit_df=load_rake_hist_by_unit_df(min_date,max_date)\n",
    "    rake_hist_by_vehicle_df=load_rake_hist_by_vehicle_df(min_date,max_date)\n",
    "    #rake_hist_df = load_rake_history() #wrong\n",
    "    #rake_hist_df=load_rake_hist_df(min_date,max_date)  #wrong\n",
    "    number_regex = r'([a-zA-Z]+)?(\\d+)'\n",
    "    \n",
    "    #TRISTAN\n",
    "    # join_exp_vehicle = (\n",
    "    #     (F.regexp_extract(df.System_Name, number_regex, 2) == rake_hist_df.Vehicle) &\n",
    "    #     (df.Date == rake_hist_df.Rake_Date) \n",
    "    # )    \n",
    "    \n",
    "    #STEVEN\n",
    "    join_exp_vehicle = (\n",
    "        (F.regexp_extract(df.System_Name, number_regex, 2) == rake_hist_by_vehicle_df.Vehicle) &\n",
    "        (df.Date == rake_hist_by_vehicle_df.Rake_Date) \n",
    "    )   \n",
    "\n",
    "    #TRISTAN\n",
    "    # join_exp_unit = (\n",
    "    #     (F.regexp_extract(df.System_Name, number_regex, 2) == rake_hist_df.Unit) &\n",
    "    #     (df.Date == rake_hist_df.Rake_Date)\n",
    "    # )\n",
    "\n",
    "    #STEVEN\n",
    "    join_exp_unit = (\n",
    "        (F.regexp_extract(df.System_Name, number_regex, 2) == rake_hist_by_unit_df.Unit) &\n",
    "        (df.Date == rake_hist_by_unit_df.Rake_Date)\n",
    "    )\n",
    "\n",
    "    df_with_rake_unit = df.join(rake_hist_by_vehicle_df, join_exp_vehicle, \"left\")\n",
    "    #df_with_rake_history = df_with_rake_unit(rake_hist_by_unit_df, join_exp_unit, \"left\")\n",
    "    df_with_rake_history = df_with_rake_unit.join(rake_hist_by_unit_df, join_exp_unit, \"left\")\n",
    "    return df_with_rake_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "220ea072-3c1a-4da7-bd3b-b1c78e26eba1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def filter_icomera_assets(df: DataFrame) -> DataFrame:\n",
    "    icomera_assets = [*SYSTEM_ID_TO_ASSET_MAP.values()]\n",
    "\n",
    "    return (\n",
    "        df.filter(\n",
    "            (F.col(\"Unit\").isin(icomera_assets) | (F.col(\"Vehicle\").isin(icomera_assets))) &\n",
    "            (F.col(\"Date\") > '2021-01-01')\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "396cf291-1ff4-4ab2-abb0-885dc3246c88",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class Upsert:\n",
    "    def __init__(self, update_condition_string=None, delta_table_path=None):\n",
    "        self.update_condition_string = update_condition_string\n",
    "        self.delta_table_path = delta_table_path\n",
    "\n",
    "    def _transform_bronze(self, df: DataFrame) -> DataFrame:\n",
    "        transformed_bronze_df = (\n",
    "            # Convert JSON body string into struct\n",
    "\n",
    "            df.withColumn(\n",
    "                \"Body_JSON\", F.from_json(F.col(\"Body_Decoded\"), JSON_SCHEMA)\n",
    "            )\n",
    "            .drop(\"body\", \"Body_Decoded\")  # no longer need the body in bytes, JSON string, or System ID (included in dataPoint)\n",
    "            .select(\n",
    "                F.col(\"*\"),\n",
    "                F.col(\"Body_JSON.*\"),\n",
    "                F.explode(\"Body_JSON.dataPoint\").alias(\"Data_Point_Exploded\")\n",
    "                # unpack each element of the array dataPoint into its own row\n",
    "            )\n",
    "            .drop(\"dataPoint\", \"Body_JSON\", \"system_ID\")\n",
    "            .withColumnRenamed(\"p_Ingest_Date\", \"Ingest_Date\")\n",
    "            .withColumnRenamed(\"type\", \"Payload_Type\")\n",
    "            .select(\n",
    "                F.col(\"*\"),\n",
    "                F.col(\"Data_Point_Exploded.*\")\n",
    "            )\n",
    "            .drop(\"Data_Point_Exploded\")\n",
    "            .withColumnRenamed(\"type\", \"Datapoint_Type\")\n",
    "            .select(\n",
    "                F.col(\"*\"),\n",
    "                F.col(\"position.*\")\n",
    "            )\n",
    "            .drop(\"position\")\n",
    "            .dropDuplicates([\"system_ID\", \"time\"])\n",
    "\n",
    "            # rename fields as per Governance\n",
    "            .withColumnRenamed(\"partition\", \"Partition\")\n",
    "            .withColumnRenamed(\"offset\", \"Offset\")\n",
    "            .withColumnRenamed(\"sequenceNumber\", \"Sequence_Number\")\n",
    "            .withColumnRenamed(\"enqueuedTime\", \"Enqueued_Time\")\n",
    "            .withColumnRenamed(\"publisher\", \"Publisher\")\n",
    "            .withColumnRenamed(\"partitionKey\", \"Partition_Key\")\n",
    "            .withColumnRenamed(\"properties\", \"Properties\")\n",
    "            .withColumnRenamed(\"systemProperties\", \"System_Properties\")\n",
    "            .withColumnRenamed(\"events\", \"Events\")\n",
    "            .withColumnRenamed(\"supplier\", \"Supplier\")\n",
    "            .withColumnRenamed(\"sentAt\", \"Sent_At\")\n",
    "            .withColumnRenamed(\"mode\", \"Mode\")\n",
    "            .withColumnRenamed(\"time\", \"Unix_Time\")\n",
    "            .withColumnRenamed(\"numberOfSatellites\", \"Number_Of_Satellites\")\n",
    "            .withColumnRenamed(\"system\", \"System\")\n",
    "            .withColumnRenamed(\"system_name\", \"System_Name\")\n",
    "            .withColumnRenamed(\"cmg\", \"CMG\")\n",
    "            .withColumnRenamed(\"speed\", \"Speed\")\n",
    "            .withColumnRenamed(\"age\", \"Age\")\n",
    "            .withColumnRenamed(\"system_ID\", \"System_ID\")\n",
    "            .withColumnRenamed(\"altitude\", \"Altitude\")\n",
    "            .withColumnRenamed(\"latitude\", \"Latitude\")\n",
    "            .withColumnRenamed(\"longitude\", \"Longitude\")\n",
    "            .withColumnRenamed(\"type\", \"Position_Type\")\n",
    "            .withColumnRenamed(\"deviceCount\", \"Device_Count\")\n",
    "\n",
    "            # casting\n",
    "            .withColumn(\"Sent_At\", F.to_timestamp(F.trim(F.col(\"Sent_At\")), \"yyyy/MM/dd HH:mm\"))\n",
    "            .withColumn(\"Enqueued_Time\", F.to_timestamp(F.col(\"Enqueued_Time\"), \"yyyy-MM-dd'T'HH:mm:ss.SSSZ\"))\n",
    "            .withColumn(\"Unix_Time\", (F.col(\"Unix_Time\")).cast('integer'))\n",
    "            .withColumn(\"CMG\", (F.col(\"CMG\")).cast('float'))\n",
    "            .withColumn(\"Device_Count\", (F.col(\"Device_Count\")).cast('integer'))\n",
    "            .withColumn(\"Speed\", (F.col(\"Speed\")).cast('float'))\n",
    "            .withColumn(\"Age\", (F.col(\"Age\")).cast('integer'))\n",
    "            .withColumn(\"Altitude\", (F.col(\"Altitude\")).cast('float'))\n",
    "            .withColumn(\"Latitude\", (F.col(\"Latitude\")).cast('float'))\n",
    "            .withColumn(\"Longitude\", (F.col(\"Longitude\")).cast('float'))\n",
    "            # derived columns\n",
    "            .withColumn(\"Timestamp\",\n",
    "                        F.to_timestamp(F.from_unixtime(F.col(\"Unix_Time\"), \"yyyy-MM-dd HH:mm:ss\"),\n",
    "                                       \"yyyy-MM-dd HH:mm:ss\"))\n",
    "            .withColumn('Date', F.to_date(F.from_unixtime(F.col(\"Unix_Time\"))))\n",
    "            .withColumn(PARTITION_COLUMN, F.col('Date'))\n",
    "        )\n",
    "        return add_rake_metadata(transformed_bronze_df)\n",
    "\n",
    "    def _transform_silver(self, df: DataFrame) -> DataFrame:\n",
    "        return (\n",
    "            df\n",
    "        )\n",
    "\n",
    "    def _upsert_to_delta(self, micro_batch_df, batch, func: Callable[[DataFrame], None]):\n",
    "        # merge microbatch into target table\n",
    "\n",
    "        from delta.tables import DeltaTable\n",
    "\n",
    "        if (self.update_condition_string is None) or (self.delta_table_path is None):\n",
    "            return False\n",
    "\n",
    "        delta_table = DeltaTable.forPath(spark, self.delta_table_path)\n",
    "\n",
    "        transformed_df = func(micro_batch_df)\n",
    "\n",
    "        (delta_table.alias('table')\n",
    "         .merge(\n",
    "            transformed_df.alias('updates'),\n",
    "            self.update_condition_string\n",
    "        )\n",
    "         .whenNotMatchedInsertAll()\n",
    "         .execute()\n",
    "         )\n",
    "\n",
    "    def upsert_to_silver(self, micro_batch_df, batch):\n",
    "        self._upsert_to_delta(micro_batch_df, batch, self._transform_bronze)\n",
    "\n",
    "    def upsert_to_silver_unified(self, micro_batch_df, batch):\n",
    "        self._upsert_to_delta(micro_batch_df, batch, self._transform_silver)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "operations",
   "notebookOrigID": 3402905892269167,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
